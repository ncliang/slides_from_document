from typing import Optional, Dict, Any, List

import requests
from langchain.callbacks.manager import CallbackManagerForLLMRun
from langchain.llms.base import LLM
from langchain.utils import get_from_dict_or_env
from pydantic import Extra, root_validator


class FormosaFoundationModel(LLM):
    """Langchain wrapper for Formosa Foundation Model"""

    model: str = "tlb81xts"

    frequence_penalty: float = 1.0
    max_new_tokens: int = 350
    temperature: float = 0.01
    top_k: int = 1
    top_p: float = 0.01

    ffm_api_key: Optional[str] = None
    base_url: Optional[str] = None
    """Base url to use, if None decides based on model name."""


    class Config:
        """Configuration for this pydantic object."""

        extra = Extra.forbid

    @root_validator()
    def validate_environment(cls, values: Dict) -> Dict:
        """Validate that api key exists in environment."""
        ffm_api_key = get_from_dict_or_env(values, "ffm_api_key", "FFM_API_KEY")
        values["ffm_api_key"] = ffm_api_key
        return values

    @property
    def _default_params(self) -> Dict[str, Any]:
        """Get the default parameters for calling AI21 API."""
        return {
            "temperature": self.temperature,
            "frequence_penalty": self.frequence_penalty,
            "max_new_tokens": self.max_new_tokens,
            "top_k": self.top_k,
            "top_p": self.top_p
        }

    @property
    def _identifying_params(self) -> Dict[str, Any]:
        """Get the identifying parameters."""
        return {**{"model": self.model}, **self._default_params}

    @property
    def _llm_type(self) -> str:
        """Return type of llm."""
        return "ffm"

    def _call(
        self,
        prompt: str,
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
        **kwargs: Any,
    ) -> str:
        """Call out to FFM's complete endpoint.

        Args:
            prompt: The prompt to pass into the model.
            stop: Optional list of stop words to use when generating.

        Returns:
            The string generated by the model.

        Example:
            .. code-block:: python

                response = ai21("Tell me a joke.")
        """
        if self.base_url is not None:
            base_url = self.base_url
        else:
            base_url = f"https://ffm-trial02.twcc.ai/text-generation/api/models"
        params = {**self._default_params, **kwargs}
        response = requests.post(
            url=f"{base_url}/{self.model}/generate",
            headers={"Authorization": f"Bearer {self.ffm_api_key}"},
            json={"inputs": prompt, "parameters": params},
        )
        if response.status_code != 200:
            optional_detail = response.json().get("detail")
            raise ValueError(
                f"FFM /generate call failed with status code {response.status_code}."
                f" Details: {optional_detail}"
            )
        response_json = response.json()
        return response_json["generated_text"]
